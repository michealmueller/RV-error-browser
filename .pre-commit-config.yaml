repos:
-   repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.4.0
    hooks:
    -   id: trailing-whitespace
    -   id: end-of-file-fixer
    -   id: check-yaml
    -   id: check-added-large-files
    -   id: check-ast
    -   id: check-json
    -   id: check-merge-conflict
    -   id: detect-private-key

-   repo: https://github.com/psf/black
    rev: 23.7.0
    hooks:
    -   id: black
        language_version: python3.11

-   repo: https://github.com/pycqa/isort
    rev: 5.12.0
    hooks:
    -   id: isort
        args: ["--profile", "black"]

-   repo: https://github.com/pycqa/flake8
    rev: 6.1.0
    hooks:
    -   id: flake8
        additional_dependencies: [flake8-docstrings]

-   repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.5.1
    hooks:
    -   id: mypy
        additional_dependencies: [types-setuptools, types-requests]
        args: [--ignore-missing-imports]

-   repo: local
    hooks:
    -   id: archive-codebase
        name: Archive and Index Codebase
        entry: |
          python -c "
          import os, json, tarfile, hashlib
          from datetime import datetime
          from pathlib import Path

          def get_file_metadata(file_path):
              stat = file_path.stat()
              with open(file_path, 'rb') as f:
                  file_hash = hashlib.sha256(f.read()).hexdigest()
              return {
                  'path': str(file_path),
                  'size': stat.st_size,
                  'modified': stat.st_mtime,
                  'sha256': file_hash
              }

          def create_index(root_dir):
              index = {
                  'timestamp': datetime.now().isoformat(),
                  'files': [],
                  'directories': []
              }
              for path in root_dir.rglob('*'):
                  if path.is_file() and not path.name.startswith('.'):
                      index['files'].append(get_file_metadata(path))
                  elif path.is_dir() and not path.name.startswith('.'):
                      index['directories'].append(str(path))
              return index

          def create_archive():
              root_dir = Path.cwd()
              output_dir = root_dir / 'archives'
              output_dir.mkdir(exist_ok=True)
              
              timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
              archive_name = f'docs_archive_{timestamp}.tar.gz'
              archive_path = output_dir / archive_name
              
              index = create_index(root_dir)
              index_path = output_dir / 'index.json'
              with open(index_path, 'w') as f:
                  json.dump(index, f, indent=2)
              
              with tarfile.open(archive_path, 'w:gz') as tar:
                  for path in root_dir.rglob('*'):
                      if (path.is_file() and 
                          not path.name.startswith('.') and 
                          'archives' not in path.parts and
                          '.git' not in path.parts):
                          tar.add(path, arcname=path.relative_to(root_dir))
                  tar.add(index_path, arcname='index.json')
              
              archives = sorted(output_dir.glob('docs_archive_*.tar.gz'))
              if len(archives) > 5:
                  for old_archive in archives[:-5]:
                      old_archive.unlink()
              
              index_path.unlink()
              print(f'Created archive: {archive_path}')

          create_archive()
          "
        language: python
        types: [python]
        pass_filenames: false 